import Chat from '../components/chat'

# Prompt Engineering

## What is prompting and why does it matter?

<mark>The key to harnessing the power of generative AI lies in crafting effective prompts</mark>, a practice often referred to as prompt engineering. This guide will walk you through the art and science of prompt engineering, providing tips and examples to help you get the most out of these advanced language models. Prompt engineering involves crafting, iterating, and refining prompts to elicit the desired response from a generative AI. It is both an art and a science, requiring creativity and precision.

<mark>Crafting effective prompts is essential for getting the best results from generative AI.</mark> By being clear, providing context, and guiding the AI with delimiters, you can significantly improve the quality of the responses. Remember, prompt engineering is an iterative process—refine your prompts based on the outputs you receive to continually enhance your interactions with these powerful tools.

## Best Practices When Prompting

- **Garbage in, garbage out**: Unclear context or difficult to understand prompts reduce the quality of the answer.

- **Be clear and precise**: All necessary information and context for the desired answer should be included.

- **Use correct grammar and spelling**: Correct grammar helps to accurately interpret the request.

- **Keep prompts short**: Avoid superfluous information to focus on the essentials and relevant keywords.
  One topic per conversation: Frequent changes of topic lead more easily to incorrect or irrelevant answers.

## Overview on Prompt Engineering

- [Assign the model a job](/prompting/assign_job.mdx) explains *role-prompting* to narrow down the desired solution early in the prompt by defining a specific role for the AI.
- [Instruct the model throughout the prompt](/prompting/instruct.mdx) provides guidance on how to give clear and continuous instructions to the AI for better responses.
- [Use delimiters and special tokens?](/prompting/use_delimiters.mdx) describes how to use symbols and tags to structure the prompt and reduce ambiguity.
- [Give the model time to think](/prompting/chain_of_thought_prompting.mdx) introduces *Chain-of-Thought* techniques for encouraging the AI to explain its reasoning step-by-step.
- [Provide examples to guide the output](/prompting/give_examples.mdx) shows how to use few-shot prompting to illustrate the desired response style and format.
- [Further Resources on Prompt Engineering](/prompting/further_resources.mdx) offers additional materials and references for deepening your understanding of prompt engineering.

---

## Example prompts you can try right now

**Answer a question**


<Chat 
  userMessage='What is the capital of France?' 
  assistantMessage='The capital of France is Paris.' 
/>

---

**Solve a Logical Problem**

<Chat 
  userMessage='Solve this logical puzzle: If all bloops are razzles and all razzles are
      fizzles, are all bloops fizzles?' 
  assistantMessage='Yes, all bloops are fizzles. This is a classic example of the transitive
      property in logic. Here’s how it works: We know that all bloops are
      razzles. We also know that all razzles are fizzles. If every bloop is a
      razzle and every razzle is a fizzle, then by transitivity, every bloop
      must also be a fizzle.' 
/>

---

**Summarize a Paragraph into a Single Sentence**

Prompt: `Summarize the following paragraph into a single sentence: [...]`

Output: “[…]”

---

**Rewrite a Paragraph into a Funny Style**

Prompt: `Rewrite the following paragraph in a humorous style: [Insert paragraph here]`

Output: “[…]”

---
