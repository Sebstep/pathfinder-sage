# Why AI Detection Does not Work

AI detection tools designed to identify whether a piece of writing was generated by artificial intelligence face significant challenges in educational settings. These tools often fail to deliver consistent, reliable results due to the inherent complexity of natural language, the adaptive capabilities of AI models, and the limitations of current detection technologies.

### Lack of Accuracy

Notably, <mark>AI detection systems are prone to both false positives and false negatives</mark>.

- **False positives** occur when authentic student work is mistakenly flagged as AI-generated. This is particularly problematic because it undermines trust between students and educators and can lead to unwarranted academic penalties. 
- On the other hand, **false negatives** happen when AI-generated text is undetected, allowing students to bypass scrutiny. 

These inaccuracies are compounded by the diversity of student writing styles and levels of proficiency, which detection systems often struggle to account for.

### Evolving AI Capabilities

AI language models, such as GPT-based systems, are continually improving in generating human-like text. As these models become more sophisticated, their outputs increasingly resemble genuine human writing, making them harder to distinguish. Moreover, students can edit or “humanize” AI-generated content, further blurring the line between machine-produced and original work. Detection systems, which rely on identifying patterns or markers typical of AI output, are often a step behind in adapting to these advances.

This rapid progress makes it difficult to stay ahead. While some educators attempt to avoid AI’s influence through in-person exams or tightly controlled assessment environments, such approaches raise logistical issues and limit opportunities for authentic assessment. Likewise, <span mark-color="red">trying to “outrun” AI by designing tasks it cannot complete is becoming increasingly unrealistic</span> due to the speed of AI advancements.

### Ethical and Pedagogical Concerns

Relying on AI detection tools can create an adversarial environment, where students feel they are being policed rather than supported in their learning journey. This <mark>focus on surveillance detracts from fostering genuine engagement with educational material</mark>. Additionally, over-reliance on detection tools may shift the emphasis away from teaching critical thinking, ethical use of technology, and the development of original ideas—skills that are fundamental to education.

Initial concerns about AI in education have often echoed longstanding anxieties surrounding essay mills, focused primarily on the fear that students might use AI to complete essays or assignments. While these concerns are valid—particularly as AI systems become more capable—the scope of generative AI’s impact is much broader, affecting a range of assessment types and challenging traditional approaches to academic integrity.

### Alternative Approaches

Instead of focusing on imperfect detection tools, educators can <mark>emphasize teaching students how to responsibly use AI as a collaborative tool</mark> in their learning process. Transparent guidelines on the acceptable use of AI for brainstorming, drafting, or problem-solving can help maintain academic integrity while leveraging the potential of these technologies.

Many educators are now choosing to <mark>embrace and adapt</mark>, creating assessments that incorporate AI in meaningful, ethical ways. **Oral examinations, iterative drafts, and process-based assessments** can help educators evaluate student understanding more effectively than relying solely on AI detection. By designing assignments that focus on the development of ideas, personal reflection, and critical engagement, educators can <mark>create tasks where the value lies in the process as much as the final product</mark>.

The most immediate and practical step is for <mark>staff to actively engage with generative AI themselves</mark>. By experimenting with these tools, educators can better understand how their assessments may be impacted and adapt accordingly. Simultaneously, institutions should develop clear strategies for AI, review and update relevant policies, and communicate transparent guidance to students.

Ultimately, moving beyond detection towards thoughtful integration of AI into teaching and assessment practices offers a more sustainable and educationally meaningful path forward.
