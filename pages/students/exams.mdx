import { Callout } from 'nextra/components'

## How to Assess Learning in the Age of AI

Traditional assessments that focus solely on final written products are becoming increasingly vulnerable to automation. As we have discussed in our article on why [AI Detection Does not Work](/genai/ai_detection.mdx), we educators need to rethink how we assess student learning in ways that embrace the presence of AI, rather than attempting to prohibit it.

Across all of these modalities, the key is to <mark>move beyond assessing only *what* students know, and instead assess *how* they think, communicate, and develop ideas</mark>. Incorporating transparency, reflection, iteration, and verbal articulation into your assessments will help you navigate the age of AI with integrity and purpose. Rather than seeing AI as a threat to learning, we can use it as an opportunity to enhance critical thinking, encourage authentic engagement, and better prepare our students for the world they will inherit.

### Emphasize Process Over Product

Iterative assignments, where students <mark>submit work in stages, receive feedback, and then revise</mark>, make it harder to rely solely on AI and instead reward sustained effort and learning over time. This approach can be applied to essays, projects, or problem sets and encourages students to engage deeply with the material. Feedback loops, peer reviews, and check-in points along the way not only support learning but also build assessment integrity by documenting the journey as well as the destination.

Another effective method is to require students to <mark>work in collaborative online environments</mark> where their writing and editing process is transparent. Platforms like Microsoft Office365 or Google Docs allow educators to <mark>view version histories, making the evolution of a student’s thinking and writing visible</mark>. Instead of only assessing the final submission, teachers can examine how ideas were developed and refined over time. Students might be asked to annotate their own changes, explaining what was revised and why, or submit a reflective commentary to accompany their document. This encourages metacognitive awareness and deters wholesale use of AI tools to produce final outputs.

Portfolio assessments are another valuable modality, especially when accompanied by structured reflection. A well-curated portfolio invites students to showcase a body of work over time, including drafts, feedback, and revisions, along with narrative reflections that make their learning visible. This format allows for a more holistic view of student growth and enables educators to see not just what was produced, but how and why. Portfolios can also include a range of media—videos, diagrams, written pieces, or peer interactions—broadening the scope of expression and supporting multiple learning styles.

### Prioritize Verbal and Performance-Based Assessments

Asking students to explain their understanding aloud, through presentations, oral exams, class debates, or role-play activities, helps <mark>ensure that they can articulate and apply knowledge in real time</mark>. These formats are resistant to AI-generated substitution, especially when interactive elements such as follow-up questions are introduced. Educators can use clear rubrics to assess both content and communication skills, and may wish to record these assessments for moderation or feedback purposes.

For disciplines that involve application and decision-making, <mark>simulation-based and scenario-driven assessments</mark> can be highly effective. Whether in business, education, medicine, or the social sciences, students can be asked to respond to realistic, unfolding situations where they must make choices, justify decisions, and adapt to new information. These tasks are inherently dynamic and difficult to automate with AI, especially if carried out in live settings or under timed conditions. They also help students connect theoretical knowledge with practical challenges—an essential outcome in most professions.

### Design Assignments that Intentionally Include AI

Students can be asked to use AI to <mark>generate a first draft or a range of responses, and then analyze or critique</mark> the quality of those outputs. They might reflect on what they would accept, reject, or revise, and explain the reasoning behind their choices. These tasks assess higher-order thinking: interpretation, judgment, and revision—all areas where human insight remains essential. In this model, AI becomes a foil for critical engagement rather than a shortcut to avoid it.

Finally, visual and conceptual mapping tasks offer a unique form of assessment that is not easily replicable by AI. Asking students to <mark>create diagrams, flowcharts, or concept maps</mark> to explain relationships between ideas tests their understanding in a different and often deeper way. These can be accompanied by written or verbal explanations to further demonstrate comprehension. Because these tasks require synthesis and organization, they help educators assess how well students understand underlying structures and frameworks, not just surface facts.
