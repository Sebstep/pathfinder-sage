# How to Assess Learning in the Age of AI

Traditional assessments that focus solely on final written products are becoming increasingly vulnerable to automation. As we have discussed in our article on why [AI Detection Does not Work](/genai/ai_detection.mdx), we need to rethink how we assess student learning in ways that embrace, rather than attempt to prohibit, the presence of AI tools.

Across all of these modalities, the key is to <mark>move beyond assessing *what* students know, and instead assess *how* they think, communicate, and develop ideas</mark>. By designing assessments that prioritize transparency, reflection, iteration, and articulation, we promote deeper learning and design for academic integrity. Rather than seeing AI as a threat to learning, we can reframe it as an opportunity to develop critical thinking and prepare for a world where AI will be ever-present.

## Emphasize Process Over Product

Iterative assignments, where students <mark>submit work in stages, receive feedback, and then revise</mark>, discourage one-off AI-generated submissions and reward sustained engagement over time. This can apply to essays, research projects, problem sets, or even multimedia work. Embedding multiple feedback points and revision cycles not only improves learning outcomes but also creates a clear audit trail of a student’s intellectual development.

Similarly, having students work in collaborative online environments like Microsoft OneDrive or Google Docs makes their writing and editing process visible. These platforms <mark>track version histories and edits to observe the progression of ideas</mark>. To deepen engagement, students can be asked to:

- Annotate key revisions and explain their rationale.
- Submit a reflective log or process journal alongside their work.
- Participate in peer review rounds with structured prompts.

This process-oriented approach encourages metacognitive awareness and deters wholesale use of AI tools to produce final outputs.

Portfolio assessments <mark>extend this model across multiple assignments</mark> or an entire term. A curated portfolio might include early drafts, feedback responses, multimedia evidence, and reflective commentary, offering a rich view into student growth and self-awareness. Portfolios allow for varied expressions of learning and can be tailored to suit discipline-specific goals, whether in the arts, sciences, or humanities.

## Prioritize Verbal and Performance-Based Assessments

Asking students to explain their understanding aloud, through presentations, oral exams, class debates, or role-play activities, helps <mark>ensure that they can articulate and apply knowledge in real time</mark>. These formats are fairly resistant to AI-generated substitution, particularly when they involve interactive questioning or discussion. Using clear, rubric-based assessment criteria ensures fairness while focusing on both content mastery and communication skills. 

For disciplines that involve application and decision-making, <mark>simulation-based and scenario-driven assessments</mark> can be highly effective. Whether in business, education, medicine, or the social sciences, students can be asked to respond to realistic, unfolding situations where they must make choices, justify decisions, and adapt to new information. Make sure to debrief after the activity, asking students to reflect on their decisions, actions, and learning. 

## Design Assignments that Intentionally Include AI

Educators can design assignments that require students to use AI tools as part of their academic work, making the human aspects of reasoning, judgment, and creativity the focus of assessment. This approach promotes digital literacy and responsible AI use. To be most effective, these assignments must be structured to <mark>guide students in *why* they use AI, *how* they use it, and *what* they learn</mark> from the experience.

### Clearly defining AI's role

To begin, instructors should clearly define the purpose of using AI in a given task. Is it a tool for ideation? For critique? For comparison? Explicitly framing the AI’s role helps students engage with it more intentionally. For example, in writing-intensive courses, students might be asked to use an AI tool to generate a first draft or outline based on a prompt. However, <mark>rather than submitting the AI-generated content, the student’s task is to analyze its quality</mark>, identify weaknesses, and revise it substantially. The final submission should include not only the revised product, but also a reflective commentary outlining what was changed and why. This encourages students to demonstrate both subject knowledge and editorial judgment.

### Using AI for ideation and research

In other cases, students can be asked to interact with AI during the research or planning phase of a project. For example, students might prompt an AI to suggest possible angles for a research paper, generate a list of counterarguments to a position, or brainstorm possible titles and structures. They would then be required to <mark>document their interactions with the AI</mark> (for instance, by submitting screenshots of their prompts and outputs) and explain how the AI’s suggestions influenced their thinking. The goal here is not to offload creative work to the machine, but to use it as a sounding board that stimulates critical engagement and helps students refine their own ideas.

Another powerful approach is to have students <mark>critique AI-generated responses alongside human-written ones</mark>. In this model, students might be given an AI-generated essay and asked to evaluate its coherence, evidence, originality, and rhetorical effectiveness compared to a peer submission or instructor-written sample. This comparative lens helps students practice evaluation, develop disciplinary standards, and articulate the qualities of strong academic work. Importantly, students learn to see both the potential and the limits of AI-generated content, reinforcing the value of human insight.

### Creating multimodal artifacts

Assignments can also ask students to use AI tools to create artifacts beyond text, such as concept maps, diagrams, flowcharts, concept maps, visual summaries, or timelines. Asking students to <mark>create visual artifacts to explain relationships between ideas</mark> tests their understanding in a different and often deeper way. These multimodal tasks are especially effective in assessing synthesis and structural understanding, and they highlight how human learners add value through interpretation and context.

### Reflecting on ethical and societal implications

In courses with an ethical or societal dimension, students can be asked to <mark>reflect on the implications of AI use in their discipline</mark>. For example, business students might evaluate how AI affects hiring or consumer targeting; education students might analyze how AI could change lesson planning or assessment; and healthcare students might discuss the risks and benefits of AI in diagnostic decision-making. Assignments might include short position papers, multimedia presentations, or even in-class debates where students argue different sides of an AI-related policy question. These tasks help students connect theory to practice and develop informed, responsible perspectives on technology.

### Providing clear guidelines

Crucially, for all AI-integrated assignments, educators should provide clear guidelines on acceptable use, attribution, and expectations. Rubrics should focus not on the AI’s output itself, but on the student’s ability to interpret, improve, and critically engage with that output. Including reflective prompts such as “What did the AI help you see differently?” or “Where did you disagree with its suggestions, and why?” supports metacognitive growth and academic honesty.

Finally, these <mark>tasks should be scaffolded</mark>, especially if students are unfamiliar with AI tools. Early assignments might introduce students to AI capabilities in low-stakes contexts, such as brainstorming or summarization, before moving on to more complex analytical or creative tasks. As students become more confident, they can be encouraged to experiment, critique, and ultimately become responsible users and co-creators alongside AI.
